# NLP-reproduction
This repository aims to offer straightforward guidance to reproduce the results from 
NLP papers. I only focus on the tasks that are not easy to reproduce with the official 
guidance, and try to obtain almost the same scores reported in papers. 

### [Summarization](summarization/README.md)
* XSum
  * Download and split [2023.03.09]
  * Evaluate fine-tuned BART [2023.03.09]
  * TODO: 
    * Finetune pre-trained BART

* CNN/DM
  * TODO:
    * Download and split 
    * Evaluate fine-tuned BART 
    * Finetune pre-trained BART


### Translation
* WMT16 En-Ro  
  * TODO:
    * Data preprocessing
    * Fintune mBART-cc25 
    * post-processing script